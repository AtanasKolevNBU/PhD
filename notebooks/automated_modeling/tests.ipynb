{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e8962a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:\\\\Repositories\\\\PhD\\\\notebooks\\\\automated_modeling', 'd:\\\\Anaconda\\\\envs\\\\ai-env-torch\\\\python310.zip', 'd:\\\\Anaconda\\\\envs\\\\ai-env-torch\\\\DLLs', 'd:\\\\Anaconda\\\\envs\\\\ai-env-torch\\\\lib', 'd:\\\\Anaconda\\\\envs\\\\ai-env-torch', '', 'd:\\\\Anaconda\\\\envs\\\\ai-env-torch\\\\lib\\\\site-packages', 'd:\\\\Anaconda\\\\envs\\\\ai-env-torch\\\\lib\\\\site-packages\\\\win32', 'd:\\\\Anaconda\\\\envs\\\\ai-env-torch\\\\lib\\\\site-packages\\\\win32\\\\lib', 'd:\\\\Anaconda\\\\envs\\\\ai-env-torch\\\\lib\\\\site-packages\\\\Pythonwin', 'D:\\\\Repositories\\\\PhD\\\\src\\\\functions', 'D:\\\\Repositories\\\\PhD\\\\src\\\\classes']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "classes_path = os.path.abspath(r\"D:\\Repositories\\PhD\\src\\classes\")\n",
    "src_path = os.path.abspath(r\"D:\\Repositories\\PhD\\src\\functions\")\n",
    "sys.path.append(src_path)\n",
    "sys.path.append(classes_path)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2c109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c8f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import agentic_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e9ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import agentic_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6172ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'agentic_modeling' from 'D:\\\\Repositories\\\\PhD\\\\src\\\\classes\\\\agentic_modeling.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(agentic_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0c59ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Demand 1</th>\n",
       "      <th>Control 1</th>\n",
       "      <th>Output Drive 1</th>\n",
       "      <th>Channel 1</th>\n",
       "      <th>Channel 2</th>\n",
       "      <th>Channel 3</th>\n",
       "      <th>Channel 4</th>\n",
       "      <th>Channel 1 Kurtosis</th>\n",
       "      <th>Channel 2 Kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th>Rear Input 5</th>\n",
       "      <th>Rear Input 6</th>\n",
       "      <th>Rear Input 7</th>\n",
       "      <th>Rear Input 8</th>\n",
       "      <th>FAULT</th>\n",
       "      <th>RPM</th>\n",
       "      <th>HUMIDITY%</th>\n",
       "      <th>TEMPERATURE_Celsius</th>\n",
       "      <th>resultant_vibration_magnitude</th>\n",
       "      <th>resultant_vibration_magnitude_normal_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.125011</td>\n",
       "      <td>0.176033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211458</td>\n",
       "      <td>0.209182</td>\n",
       "      <td>0.145823</td>\n",
       "      <td>1.624200e-15</td>\n",
       "      <td>2.52457</td>\n",
       "      <td>2.94874</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.331264</td>\n",
       "      <td>-1.104839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006283</td>\n",
       "      <td>0.125011</td>\n",
       "      <td>0.176033</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.206329</td>\n",
       "      <td>0.206513</td>\n",
       "      <td>0.150478</td>\n",
       "      <td>1.643320e-15</td>\n",
       "      <td>2.32290</td>\n",
       "      <td>2.46553</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.328425</td>\n",
       "      <td>-1.113447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009633</td>\n",
       "      <td>0.125011</td>\n",
       "      <td>0.172626</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.206351</td>\n",
       "      <td>0.194663</td>\n",
       "      <td>0.148313</td>\n",
       "      <td>1.528270e-15</td>\n",
       "      <td>2.26458</td>\n",
       "      <td>2.55488</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.320111</td>\n",
       "      <td>-1.139087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.125011</td>\n",
       "      <td>0.172626</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.214463</td>\n",
       "      <td>0.214489</td>\n",
       "      <td>0.155652</td>\n",
       "      <td>1.791370e-15</td>\n",
       "      <td>2.53380</td>\n",
       "      <td>2.66379</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.340921</td>\n",
       "      <td>-1.076103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016583</td>\n",
       "      <td>0.125011</td>\n",
       "      <td>0.172626</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.210449</td>\n",
       "      <td>0.198857</td>\n",
       "      <td>0.154162</td>\n",
       "      <td>1.594310e-15</td>\n",
       "      <td>2.51443</td>\n",
       "      <td>2.81510</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.328023</td>\n",
       "      <td>-1.114673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390057</th>\n",
       "      <td>27.302300</td>\n",
       "      <td>0.500044</td>\n",
       "      <td>0.515140</td>\n",
       "      <td>0.043543</td>\n",
       "      <td>0.554265</td>\n",
       "      <td>0.560519</td>\n",
       "      <td>1.633510</td>\n",
       "      <td>1.712510e-15</td>\n",
       "      <td>3.10602</td>\n",
       "      <td>3.09644</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>1.813766</td>\n",
       "      <td>0.595405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390058</th>\n",
       "      <td>27.305700</td>\n",
       "      <td>0.500044</td>\n",
       "      <td>0.515140</td>\n",
       "      <td>0.043541</td>\n",
       "      <td>0.554672</td>\n",
       "      <td>0.560996</td>\n",
       "      <td>1.646360</td>\n",
       "      <td>1.711110e-15</td>\n",
       "      <td>3.10423</td>\n",
       "      <td>3.09293</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>1.825617</td>\n",
       "      <td>0.601918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390059</th>\n",
       "      <td>27.309200</td>\n",
       "      <td>0.500044</td>\n",
       "      <td>0.515140</td>\n",
       "      <td>0.043536</td>\n",
       "      <td>0.555249</td>\n",
       "      <td>0.561109</td>\n",
       "      <td>1.645410</td>\n",
       "      <td>1.710140e-15</td>\n",
       "      <td>3.11372</td>\n",
       "      <td>3.09118</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>1.824971</td>\n",
       "      <td>0.601564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390060</th>\n",
       "      <td>27.312500</td>\n",
       "      <td>0.500044</td>\n",
       "      <td>0.515305</td>\n",
       "      <td>0.043532</td>\n",
       "      <td>0.555029</td>\n",
       "      <td>0.560672</td>\n",
       "      <td>1.640060</td>\n",
       "      <td>1.711640e-15</td>\n",
       "      <td>3.11269</td>\n",
       "      <td>3.09097</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>1.819947</td>\n",
       "      <td>0.598807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390061</th>\n",
       "      <td>27.315800</td>\n",
       "      <td>0.500044</td>\n",
       "      <td>0.515305</td>\n",
       "      <td>0.043526</td>\n",
       "      <td>0.554786</td>\n",
       "      <td>0.560474</td>\n",
       "      <td>1.632540</td>\n",
       "      <td>1.710060e-15</td>\n",
       "      <td>3.11065</td>\n",
       "      <td>3.09005</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>1.813038</td>\n",
       "      <td>0.595004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390062 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time  Demand 1  Control 1  Output Drive 1  Channel 1  Channel 2  \\\n",
       "0        0.001450  0.125011   0.176033        0.000000   0.211458   0.209182   \n",
       "1        0.006283  0.125011   0.176033        0.000012   0.206329   0.206513   \n",
       "2        0.009633  0.125011   0.172626        0.000013   0.206351   0.194663   \n",
       "3        0.013200  0.125011   0.172626        0.000014   0.214463   0.214489   \n",
       "4        0.016583  0.125011   0.172626        0.000015   0.210449   0.198857   \n",
       "...           ...       ...        ...             ...        ...        ...   \n",
       "390057  27.302300  0.500044   0.515140        0.043543   0.554265   0.560519   \n",
       "390058  27.305700  0.500044   0.515140        0.043541   0.554672   0.560996   \n",
       "390059  27.309200  0.500044   0.515140        0.043536   0.555249   0.561109   \n",
       "390060  27.312500  0.500044   0.515305        0.043532   0.555029   0.560672   \n",
       "390061  27.315800  0.500044   0.515305        0.043526   0.554786   0.560474   \n",
       "\n",
       "        Channel 3     Channel 4  Channel 1 Kurtosis  Channel 2 Kurtosis  ...  \\\n",
       "0        0.145823  1.624200e-15             2.52457             2.94874  ...   \n",
       "1        0.150478  1.643320e-15             2.32290             2.46553  ...   \n",
       "2        0.148313  1.528270e-15             2.26458             2.55488  ...   \n",
       "3        0.155652  1.791370e-15             2.53380             2.66379  ...   \n",
       "4        0.154162  1.594310e-15             2.51443             2.81510  ...   \n",
       "...           ...           ...                 ...                 ...  ...   \n",
       "390057   1.633510  1.712510e-15             3.10602             3.09644  ...   \n",
       "390058   1.646360  1.711110e-15             3.10423             3.09293  ...   \n",
       "390059   1.645410  1.710140e-15             3.11372             3.09118  ...   \n",
       "390060   1.640060  1.711640e-15             3.11269             3.09097  ...   \n",
       "390061   1.632540  1.710060e-15             3.11065             3.09005  ...   \n",
       "\n",
       "        Rear Input 5  Rear Input 6  Rear Input 7  Rear Input 8  FAULT   RPM  \\\n",
       "0                  0             0             0             0      1  1000   \n",
       "1                  0             0             0             0      1  1000   \n",
       "2                  0             0             0             0      1  1000   \n",
       "3                  0             0             0             0      1  1000   \n",
       "4                  0             0             0             0      1  1000   \n",
       "...              ...           ...           ...           ...    ...   ...   \n",
       "390057             0             0             0             0      0  2000   \n",
       "390058             0             0             0             0      0  2000   \n",
       "390059             0             0             0             0      0  2000   \n",
       "390060             0             0             0             0      0  2000   \n",
       "390061             0             0             0             0      0  2000   \n",
       "\n",
       "        HUMIDITY%  TEMPERATURE_Celsius  resultant_vibration_magnitude  \\\n",
       "0               0                  -10                       0.331264   \n",
       "1               0                  -10                       0.328425   \n",
       "2               0                  -10                       0.320111   \n",
       "3               0                  -10                       0.340921   \n",
       "4               0                  -10                       0.328023   \n",
       "...           ...                  ...                            ...   \n",
       "390057         50                   45                       1.813766   \n",
       "390058         50                   45                       1.825617   \n",
       "390059         50                   45                       1.824971   \n",
       "390060         50                   45                       1.819947   \n",
       "390061         50                   45                       1.813038   \n",
       "\n",
       "        resultant_vibration_magnitude_normal_dist  \n",
       "0                                       -1.104839  \n",
       "1                                       -1.113447  \n",
       "2                                       -1.139087  \n",
       "3                                       -1.076103  \n",
       "4                                       -1.114673  \n",
       "...                                           ...  \n",
       "390057                                   0.595405  \n",
       "390058                                   0.601918  \n",
       "390059                                   0.601564  \n",
       "390060                                   0.598807  \n",
       "390061                                   0.595004  \n",
       "\n",
       "[390062 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\Repositories\\PhD\\parsed_data\\ICE_data\\internal_combustion_engine_bearings_fixed_duplicates.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c0c261",
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = df['Channel 3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6992d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe2 = agentic_processing.PipelineExecutor.load(r\"D:\\Repositories\\PhD\\notebooks\\automated_processing\\best_preproc.joblib\")\n",
    "y_new = pe2.transform(c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83de2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb660690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.20000e+01, 3.09000e+02, 7.11800e+03, 5.11440e+04, 1.34442e+05,\n",
       "        1.38347e+05, 5.08900e+04, 7.41600e+03, 3.72000e+02, 1.20000e+01]),\n",
       " array([-5.19933758e+00, -4.15947007e+00, -3.11960255e+00, -2.07973503e+00,\n",
       "        -1.03986752e+00,  4.89217555e-11,  1.03986752e+00,  2.07973503e+00,\n",
       "         3.11960255e+00,  4.15947007e+00,  5.19933758e+00]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1592f2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390062,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e8afcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = y_new.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "754e1c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df['FAULT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7961ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff460ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d22b8944",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "StudyRunner.__init__() missing 2 required positional arguments: 'objective' and 'cv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sr \u001b[38;5;241m=\u001b[39m \u001b[43magentic_modeling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStudyRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: StudyRunner.__init__() missing 2 required positional arguments: 'objective' and 'cv'"
     ]
    }
   ],
   "source": [
    "sr = agentic_modeling.StudyRunner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76645c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function agentic_modeling.optuna_objective(trial, X, y, weights=None, n_splits=5)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_modeling.optuna_objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a239a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 13:18:19,850] A new study created in memory with name: no-name-fe50feea-bd39-408b-a5ec-8cab05669468\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))\n",
    "study.optimize(lambda t: agentic_modeling.optuna_objective(t, y_new, label,\n",
    "                  weights=weights, n_splits=5),\n",
    "               n_trials=100)\n",
    "\n",
    "\n",
    "print(\"Best score:\", study.best_value)\n",
    "print(\"Best config:\", study.best_trial.params)\n",
    "cfg = study.best_trial.user_attrs if \"config\" in study.best_trial.user_attrs else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13ba2b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6ec7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = y_new, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eafbddaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 15:03:40,048] A new study created in memory with name: no-name-e8433ac3-93ea-4426-a51b-0cb8aa6108ab\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 15:07:06,251] Trial 0 finished with value: 0.6571564883908099 and parameters: {'model_type': 'svc', 'svc_C': 5.1364341506195546, 'svc_kernel': 'rbf', 'svc_gamma': 0.036738741762001155}. Best is trial 0 with value: 0.6571564883908099.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 64, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6312 val_loss=0.6103\n",
      "[TorchANN] epoch 005 train_loss=0.5976 val_loss=0.5911\n",
      "[TorchANN] epoch 010 train_loss=0.5931 val_loss=0.5875\n",
      "[TorchANN] Stopping due to time budget (70s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6286 val_loss=0.6066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 005 train_loss=0.5964 val_loss=0.5889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 6 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 7 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 8 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 9 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 010 train_loss=0.5923 val_loss=0.5868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 10 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 11 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 12 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (70s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 13 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6315 val_loss=0.6127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 005 train_loss=0.5977 val_loss=0.5924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 6 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 7 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 8 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 9 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 010 train_loss=0.5921 val_loss=0.5883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 10 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 11 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 12 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (70s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 13 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6284 val_loss=0.6080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 005 train_loss=0.5973 val_loss=0.5898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 6 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 7 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 8 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 9 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 010 train_loss=0.5926 val_loss=0.5867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 10 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 11 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 12 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (70s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 13 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6296 val_loss=0.6094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 005 train_loss=0.5978 val_loss=0.5925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 6 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 7 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 8 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 9 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 010 train_loss=0.5934 val_loss=0.5892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 10 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 11 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 12 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (70s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 13 is already reported.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 15:13:13,279] Trial 1 finished with value: 0.7181868948941992 and parameters: {'model_type': 'torch', 'torch_hidden': (64, 64, 32), 'torch_dropout': 0.06982188332306549, 'torch_lr': 0.0001468030511461997, 'torch_batch': 128, 'torch_epochs': 52, 'torch_patience': 6, 'torch_fit_seconds': 70}. Best is trial 1 with value: 0.7181868948941992.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-10-21 15:15:19,616] Trial 2 finished with value: 0.7185281890726728 and parameters: {'model_type': 'mlp', 'mlp_hidden': (128,), 'mlp_act': 'relu', 'mlp_alpha': 0.0002836347578862727, 'mlp_lr': 0.003176812393259263, 'mlp_max_iter': 189}. Best is trial 2 with value: 0.7185281890726728.\n",
      "[I 2025-10-21 15:15:20,859] Trial 3 finished with value: 0.6395266134285099 and parameters: {'model_type': 'sgd', 'sgd_loss': 'log_loss', 'sgd_alpha': 0.004636965539611948, 'sgd_penalty': 'elasticnet', 'sgd_max_iter': 2692}. Best is trial 2 with value: 0.7185281890726728.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 64, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6125 val_loss=0.5979\n",
      "[TorchANN] Stopping due to time budget (38s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6124 val_loss=0.5988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (38s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6133 val_loss=0.6003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (38s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6136 val_loss=0.5964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (38s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6119 val_loss=0.6010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (38s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 15:19:39,196] Trial 4 finished with value: 0.7301524973988529 and parameters: {'model_type': 'torch', 'torch_hidden': (128, 64), 'torch_dropout': 0.41991038385017776, 'torch_lr': 0.003110692443194205, 'torch_batch': 32, 'torch_epochs': 61, 'torch_patience': 10, 'torch_fit_seconds': 38}. Best is trial 4 with value: 0.7301524973988529.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 15:26:25,371] Trial 5 finished with value: 0.6571564883908099 and parameters: {'model_type': 'svc', 'svc_C': 14.844947759557536, 'svc_kernel': 'rbf', 'svc_gamma': 0.00011065611349010632}. Best is trial 4 with value: 0.7301524973988529.\n",
      "[I 2025-10-21 15:26:28,080] Trial 6 finished with value: 0.7344651948852455 and parameters: {'model_type': 'xgb', 'xgb_n': 350, 'xgb_depth': 4, 'xgb_lr': 0.03003622429533417, 'xgb_subsample': 0.7633348393528963, 'xgb_colsample': 0.697103352572398}. Best is trial 6 with value: 0.7344651948852455.\n",
      "[I 2025-10-21 15:26:28,940] Trial 7 finished with value: 0.7031189189513563 and parameters: {'model_type': 'sgd', 'sgd_loss': 'hinge', 'sgd_alpha': 5.5771739519538785e-05, 'sgd_penalty': 'l1', 'sgd_max_iter': 4410}. Best is trial 6 with value: 0.7344651948852455.\n",
      "[I 2025-10-21 15:26:29,749] Trial 8 finished with value: 0.6539912451582759 and parameters: {'model_type': 'sgd', 'sgd_loss': 'log_loss', 'sgd_alpha': 0.00023165379848541043, 'sgd_penalty': 'l2', 'sgd_max_iter': 2367}. Best is trial 6 with value: 0.7344651948852455.\n",
      "[I 2025-10-21 15:26:32,276] Trial 9 finished with value: 0.7295079290265403 and parameters: {'model_type': 'xgb', 'xgb_n': 208, 'xgb_depth': 8, 'xgb_lr': 0.08465693760843228, 'xgb_subsample': 0.7675343064538, 'xgb_colsample': 0.6223607312140872}. Best is trial 6 with value: 0.7344651948852455.\n",
      "[I 2025-10-21 15:26:36,139] Trial 10 finished with value: 0.7543587972428273 and parameters: {'model_type': 'xgb', 'xgb_n': 499, 'xgb_depth': 3, 'xgb_lr': 0.0027647473672664535, 'xgb_subsample': 0.6014926402590652, 'xgb_colsample': 0.7758740825009873}. Best is trial 10 with value: 0.7543587972428273.\n",
      "[I 2025-10-21 15:26:39,672] Trial 11 finished with value: 0.7542347387974943 and parameters: {'model_type': 'xgb', 'xgb_n': 507, 'xgb_depth': 3, 'xgb_lr': 0.0015342704493676025, 'xgb_subsample': 0.6319514647068829, 'xgb_colsample': 0.8033841373336841}. Best is trial 10 with value: 0.7543587972428273.\n",
      "[I 2025-10-21 15:26:43,679] Trial 12 finished with value: 0.7549084088995732 and parameters: {'model_type': 'xgb', 'xgb_n': 578, 'xgb_depth': 3, 'xgb_lr': 0.0011448737077908563, 'xgb_subsample': 0.6001106645375169, 'xgb_colsample': 0.8680120242791431}. Best is trial 12 with value: 0.7549084088995732.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 15:43:57,765] Trial 13 finished with value: 0.6571564883908099 and parameters: {'model_type': 'linear_svc', 'linsvc_C': 43.939239106237515, 'linsvc_max_iter': 8953}. Best is trial 12 with value: 0.7549084088995732.\n",
      "[I 2025-10-21 15:44:01,900] Trial 14 finished with value: 0.7549103539182012 and parameters: {'model_type': 'xgb', 'xgb_n': 594, 'xgb_depth': 3, 'xgb_lr': 0.0011237122285731181, 'xgb_subsample': 0.618665421116791, 'xgb_colsample': 0.9545393776857116}. Best is trial 14 with value: 0.7549103539182012.\n",
      "[I 2025-10-21 15:44:07,362] Trial 15 finished with value: 0.7620624680862746 and parameters: {'model_type': 'xgb', 'xgb_n': 599, 'xgb_depth': 6, 'xgb_lr': 0.0010563720569249408, 'xgb_subsample': 0.9621944014761906, 'xgb_colsample': 0.9927266402190833}. Best is trial 15 with value: 0.7620624680862746.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 15:44:09,394] Trial 16 finished with value: 0.6571564883908099 and parameters: {'model_type': 'linear_svc', 'linsvc_C': 0.0011712846820865323, 'linsvc_max_iter': 2038}. Best is trial 15 with value: 0.7620624680862746.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-10-21 15:53:24,442] Trial 17 finished with value: 0.721997023526231 and parameters: {'model_type': 'mlp', 'mlp_hidden': (128, 64), 'mlp_act': 'tanh', 'mlp_alpha': 1.7444222670493568e-06, 'mlp_lr': 0.00013825704885073056, 'mlp_max_iter': 382}. Best is trial 15 with value: 0.7620624680862746.\n",
      "[I 2025-10-21 15:53:29,714] Trial 18 finished with value: 0.736015179083474 and parameters: {'model_type': 'xgb', 'xgb_n': 585, 'xgb_depth': 6, 'xgb_lr': 0.00783247985816528, 'xgb_subsample': 0.9617641539005195, 'xgb_colsample': 0.9953641103041304}. Best is trial 15 with value: 0.7620624680862746.\n",
      "[I 2025-10-21 15:53:35,204] Trial 19 finished with value: 0.7356945582276249 and parameters: {'model_type': 'xgb', 'xgb_n': 403, 'xgb_depth': 10, 'xgb_lr': 0.004446093573283206, 'xgb_subsample': 0.9848293635911358, 'xgb_colsample': 0.990639054402237}. Best is trial 15 with value: 0.7620624680862746.\n",
      "[I 2025-10-21 15:53:39,297] Trial 20 finished with value: 0.7640703670944715 and parameters: {'model_type': 'xgb', 'xgb_n': 432, 'xgb_depth': 6, 'xgb_lr': 0.0010537616327627, 'xgb_subsample': 0.8888935107374636, 'xgb_colsample': 0.9067915778459495}. Best is trial 20 with value: 0.7640703670944715.\n",
      "[I 2025-10-21 15:53:43,481] Trial 21 finished with value: 0.7635670654653384 and parameters: {'model_type': 'xgb', 'xgb_n': 442, 'xgb_depth': 6, 'xgb_lr': 0.001161853666957164, 'xgb_subsample': 0.8864411376413004, 'xgb_colsample': 0.9160683657334796}. Best is trial 20 with value: 0.7640703670944715.\n",
      "[I 2025-10-21 15:53:47,126] Trial 22 finished with value: 0.7643048761015186 and parameters: {'model_type': 'xgb', 'xgb_n': 379, 'xgb_depth': 6, 'xgb_lr': 0.0010613407030573686, 'xgb_subsample': 0.8934472376170868, 'xgb_colsample': 0.9017001921756882}. Best is trial 22 with value: 0.7643048761015186.\n",
      "[I 2025-10-21 15:53:51,089] Trial 23 finished with value: 0.7416096732783813 and parameters: {'model_type': 'xgb', 'xgb_n': 366, 'xgb_depth': 7, 'xgb_lr': 0.003535711743832391, 'xgb_subsample': 0.8723824659639622, 'xgb_colsample': 0.8927237112954163}. Best is trial 22 with value: 0.7643048761015186.\n",
      "[I 2025-10-21 15:53:54,666] Trial 24 finished with value: 0.7319074203757081 and parameters: {'model_type': 'xgb', 'xgb_n': 429, 'xgb_depth': 5, 'xgb_lr': 0.01476976986113929, 'xgb_subsample': 0.8647507145826641, 'xgb_colsample': 0.9050211007832486}. Best is trial 22 with value: 0.7643048761015186.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-10-21 15:56:21,013] Trial 25 finished with value: 0.7128944615724679 and parameters: {'model_type': 'mlp', 'mlp_hidden': (64, 64), 'mlp_act': 'tanh', 'mlp_alpha': 0.004568719738577315, 'mlp_lr': 0.009815114885561787, 'mlp_max_iter': 387}. Best is trial 22 with value: 0.7643048761015186.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 15:56:24,724] Trial 26 finished with value: 0.6571564883908099 and parameters: {'model_type': 'linear_svc', 'linsvc_C': 0.027388196240440983, 'linsvc_max_iter': 4034}. Best is trial 22 with value: 0.7643048761015186.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 64, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6007 val_loss=0.5927\n",
      "[TorchANN] epoch 005 train_loss=0.5882 val_loss=0.5872\n",
      "[TorchANN] epoch 010 train_loss=0.5863 val_loss=0.5836\n",
      "[TorchANN] Stopping due to time budget (88s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6013 val_loss=0.5928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 005 train_loss=0.5924 val_loss=0.5886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 6 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 7 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 8 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 9 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 010 train_loss=0.5917 val_loss=0.5913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 10 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (88s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 11 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6012 val_loss=0.5948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 005 train_loss=0.5902 val_loss=0.5896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 6 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 7 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 8 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 9 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 010 train_loss=0.5878 val_loss=0.5857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 10 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (88s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 11 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6014 val_loss=0.5933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 005 train_loss=0.5894 val_loss=0.5896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 6 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 7 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 8 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 9 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 010 train_loss=0.5866 val_loss=0.5844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 10 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (88s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 11 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6006 val_loss=0.5952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 005 train_loss=0.5949 val_loss=0.5971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 6 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 7 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 8 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 9 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 010 train_loss=0.5923 val_loss=0.5941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 10 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (88s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 11 is already reported.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 16:04:18,804] Trial 27 finished with value: 0.7372207016588541 and parameters: {'model_type': 'torch', 'torch_hidden': (64, 64, 32), 'torch_dropout': 0.0016029642110687303, 'torch_lr': 0.009136931442682393, 'torch_batch': 64, 'torch_epochs': 20, 'torch_patience': 12, 'torch_fit_seconds': 88}. Best is trial 22 with value: 0.7643048761015186.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 16:04:20,940] Trial 28 finished with value: 0.6571564883908099 and parameters: {'model_type': 'svc', 'svc_C': 0.0011474787771977026, 'svc_kernel': 'poly', 'svc_gamma': 0.2576493890185735}. Best is trial 22 with value: 0.7643048761015186.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 16:04:23,749] Trial 29 finished with value: 0.6571564883908099 and parameters: {'model_type': 'svc', 'svc_C': 0.0068620631230440435, 'svc_kernel': 'poly', 'svc_gamma': 0.00030394085748227105}. Best is trial 22 with value: 0.7643048761015186.\n",
      "[I 2025-10-21 16:04:26,478] Trial 30 finished with value: 0.7292522401208356 and parameters: {'model_type': 'xgb', 'xgb_n': 251, 'xgb_depth': 7, 'xgb_lr': 0.2318478304541164, 'xgb_subsample': 0.8749630089330267, 'xgb_colsample': 0.83395112753225}. Best is trial 22 with value: 0.7643048761015186.\n",
      "[I 2025-10-21 16:04:29,489] Trial 31 finished with value: 0.7661646172744876 and parameters: {'model_type': 'xgb', 'xgb_n': 299, 'xgb_depth': 6, 'xgb_lr': 0.001087140783306997, 'xgb_subsample': 0.9246377129193185, 'xgb_colsample': 0.9341779001580311}. Best is trial 31 with value: 0.7661646172744876.\n",
      "[I 2025-10-21 16:04:32,187] Trial 32 finished with value: 0.7649583202577391 and parameters: {'model_type': 'xgb', 'xgb_n': 300, 'xgb_depth': 5, 'xgb_lr': 0.00236093489144078, 'xgb_subsample': 0.8901928702777444, 'xgb_colsample': 0.9247395204186193}. Best is trial 31 with value: 0.7661646172744876.\n",
      "[I 2025-10-21 16:04:34,896] Trial 33 finished with value: 0.755926794465578 and parameters: {'model_type': 'xgb', 'xgb_n': 298, 'xgb_depth': 5, 'xgb_lr': 0.0025862250823788725, 'xgb_subsample': 0.9006134475239919, 'xgb_colsample': 0.9332386156510645}. Best is trial 31 with value: 0.7661646172744876.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 64, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6314 val_loss=0.6064\n",
      "[TorchANN] Stopping due to time budget (21s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6307 val_loss=0.6033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (21s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6298 val_loss=0.6031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (21s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6288 val_loss=0.6019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (21s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6271 val_loss=0.6033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (21s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 16:06:58,661] Trial 34 finished with value: 0.7115717263991745 and parameters: {'model_type': 'torch', 'torch_hidden': (128, 64), 'torch_dropout': 0.4618179236710348, 'torch_lr': 0.00024195850724950796, 'torch_batch': 32, 'torch_epochs': 80, 'torch_patience': 5, 'torch_fit_seconds': 21}. Best is trial 31 with value: 0.7661646172744876.\n",
      "[I 2025-10-21 16:06:59,993] Trial 35 finished with value: 0.7658773416312146 and parameters: {'model_type': 'xgb', 'xgb_n': 108, 'xgb_depth': 5, 'xgb_lr': 0.002168601953242511, 'xgb_subsample': 0.8246863572044201, 'xgb_colsample': 0.8544216048994877}. Best is trial 31 with value: 0.7661646172744876.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-10-21 16:12:23,750] Trial 36 finished with value: 0.7282085591676287 and parameters: {'model_type': 'mlp', 'mlp_hidden': (128, 64), 'mlp_act': 'relu', 'mlp_alpha': 1.5799745001378654e-06, 'mlp_lr': 0.00024248725091609798, 'mlp_max_iter': 164}. Best is trial 31 with value: 0.7661646172744876.\n",
      "[I 2025-10-21 16:12:24,888] Trial 37 finished with value: 0.5771584913326068 and parameters: {'model_type': 'sgd', 'sgd_loss': 'hinge', 'sgd_alpha': 3.811460787091141e-06, 'sgd_penalty': 'l1', 'sgd_max_iter': 1206}. Best is trial 31 with value: 0.7661646172744876.\n",
      "[I 2025-10-21 16:12:26,129] Trial 38 finished with value: 0.7658761228771835 and parameters: {'model_type': 'xgb', 'xgb_n': 105, 'xgb_depth': 5, 'xgb_lr': 0.00216560651038505, 'xgb_subsample': 0.8221401577326548, 'xgb_colsample': 0.8522317385470792}. Best is trial 31 with value: 0.7661646172744876.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 64, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6138 val_loss=0.5949\n",
      "[TorchANN] epoch 005 train_loss=0.5948 val_loss=0.5871\n",
      "[TorchANN] Stopping due to time budget (56s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6126 val_loss=0.5927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 005 train_loss=0.5930 val_loss=0.5855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 6 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (56s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 7 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6129 val_loss=0.5960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 005 train_loss=0.5945 val_loss=0.5892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 6 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (56s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 7 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6143 val_loss=0.5932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 005 train_loss=0.5939 val_loss=0.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 6 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (56s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 7 is already reported.\n",
      "  warnings.warn(\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:136: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
      "D:\\Repositories\\PhD\\src\\classes\\agentic_modeling.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 001 train_loss=0.6145 val_loss=0.5988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] epoch 005 train_loss=0.5956 val_loss=0.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 6 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchANN] Stopping due to time budget (56s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 7 is already reported.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 16:17:27,441] Trial 39 finished with value: 0.7289576414272431 and parameters: {'model_type': 'torch', 'torch_hidden': (64, 64, 32), 'torch_dropout': 0.2510725408232754, 'torch_lr': 0.0008622507647775949, 'torch_batch': 64, 'torch_epochs': 26, 'torch_patience': 8, 'torch_fit_seconds': 56}. Best is trial 31 with value: 0.7661646172744876.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 16:28:52,070] Trial 40 finished with value: 0.6571564883908099 and parameters: {'model_type': 'svc', 'svc_C': 941.0551610903885, 'svc_kernel': 'rbf', 'svc_gamma': 0.002391456976178976}. Best is trial 31 with value: 0.7661646172744876.\n",
      "[I 2025-10-21 16:28:53,339] Trial 41 finished with value: 0.7658854937969309 and parameters: {'model_type': 'xgb', 'xgb_n': 104, 'xgb_depth': 5, 'xgb_lr': 0.0022170954388745323, 'xgb_subsample': 0.8179934642156053, 'xgb_colsample': 0.8547536139441922}. Best is trial 31 with value: 0.7661646172744876.\n",
      "[I 2025-10-21 16:28:54,610] Trial 42 finished with value: 0.7659240364889278 and parameters: {'model_type': 'xgb', 'xgb_n': 105, 'xgb_depth': 5, 'xgb_lr': 0.002409567514476122, 'xgb_subsample': 0.8033621398932482, 'xgb_colsample': 0.8245266643801196}. Best is trial 31 with value: 0.7661646172744876.\n",
      "[I 2025-10-21 16:28:56,020] Trial 43 finished with value: 0.7649476542776665 and parameters: {'model_type': 'xgb', 'xgb_n': 123, 'xgb_depth': 5, 'xgb_lr': 0.005406291624344685, 'xgb_subsample': 0.8118369939739508, 'xgb_colsample': 0.8466892860759329}. Best is trial 31 with value: 0.7661646172744876.\n",
      "[I 2025-10-21 16:28:57,192] Trial 44 finished with value: 0.7654091846802558 and parameters: {'model_type': 'xgb', 'xgb_n': 100, 'xgb_depth': 4, 'xgb_lr': 0.0020196903698228848, 'xgb_subsample': 0.8148801490875468, 'xgb_colsample': 0.7873055977232052}. Best is trial 31 with value: 0.7661646172744876.\n",
      "[I 2025-10-21 16:28:58,201] Trial 45 finished with value: 0.5610964670362472 and parameters: {'model_type': 'sgd', 'sgd_loss': 'log_loss', 'sgd_alpha': 2.753023780962339e-06, 'sgd_penalty': 'elasticnet', 'sgd_max_iter': 4936}. Best is trial 31 with value: 0.7661646172744876.\n",
      "[I 2025-10-21 16:28:59,704] Trial 46 finished with value: 0.7637321843780522 and parameters: {'model_type': 'xgb', 'xgb_n': 156, 'xgb_depth': 4, 'xgb_lr': 0.006151255869670067, 'xgb_subsample': 0.7683456243369469, 'xgb_colsample': 0.8220261213961101}. Best is trial 31 with value: 0.7661646172744876.\n",
      "[I 2025-10-21 16:29:01,482] Trial 47 finished with value: 0.7660711156839243 and parameters: {'model_type': 'xgb', 'xgb_n': 164, 'xgb_depth': 5, 'xgb_lr': 0.001976263105373151, 'xgb_subsample': 0.7061537928792951, 'xgb_colsample': 0.7465818671871746}. Best is trial 31 with value: 0.7661646172744876.\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ai-env-torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2025-10-21 16:47:05,222] Trial 48 finished with value: 0.6571564883908099 and parameters: {'model_type': 'linear_svc', 'linsvc_C': 831.4301807285549, 'linsvc_max_iter': 9430}. Best is trial 31 with value: 0.7661646172744876.\n",
      "[I 2025-10-21 16:47:06,926] Trial 49 finished with value: 0.7654613506584044 and parameters: {'model_type': 'xgb', 'xgb_n': 172, 'xgb_depth': 4, 'xgb_lr': 0.0018328097007971513, 'xgb_subsample': 0.7029796778147079, 'xgb_colsample': 0.7444966390882406}. Best is trial 31 with value: 0.7661646172744876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (func): 0.7661646172744876\n",
      "Best config (func): {'model_type': 'xgb', 'params': {'n_estimators': 299, 'max_depth': 6, 'learning_rate': 0.001087140783306997, 'subsample': 0.9246377129193185, 'colsample_bytree': 0.9341779001580311}}\n"
     ]
    }
   ],
   "source": [
    "weights = {\"accuracy\": 0.1, \"precision\": 0.3, \"recall\": 0.3, \"f1\": 0.2, \"roc_auc\": 0.1}\n",
    "study = optuna.create_study(direction=\"maximize\",\n",
    "                            pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))\n",
    "study.optimize(lambda t: agentic_modeling.optuna_objective(t, X, y, weights, n_splits=5), n_trials=50)\n",
    "print(\"Best score (func):\", study.best_value)\n",
    "print(\"Best config (func):\", study.best_trial.user_attrs[\"config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a4d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
